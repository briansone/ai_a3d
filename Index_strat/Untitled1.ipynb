{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from Functions.conn import db_upload\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = [ 'Datums', 'ASA51', 'XNDX', 'SPXT', 'CACR', 'DAX', 'NKYTR', 'HSI1', 'KSP2TR']\n",
    "subset = [ 'ASA51', 'XNDX', 'SPXT', 'CACR', 'DAX', 'NKYTR', 'HSI1', 'KSP2TR' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingData size is \n",
      "64\n",
      "[[0.00000000e+00 9.57108034e-01 8.99824766e-01 1.86206029e-01\n",
      "  6.18372508e-01 6.37542177e-01 8.69045299e-02 0.00000000e+00]\n",
      " [1.52974649e-01 1.00000000e+00 1.00000000e+00 2.44415078e-01\n",
      "  6.99830038e-01 8.37400107e-01 1.80151610e-01 2.17270195e-01]\n",
      " [2.27347294e-01 8.40205384e-01 9.63006231e-01 5.04310616e-01\n",
      "  7.22464038e-01 1.00000000e+00 2.30633886e-01 1.14206128e-01]\n",
      " [3.69774178e-01 2.88003734e-01 5.48383956e-01 1.00000000e+00\n",
      "  1.00000000e+00 9.89495649e-01 1.63136296e-01 1.50417827e-01]\n",
      " [2.72934663e-01 1.10160261e-01 1.96553738e-01 3.17915801e-01\n",
      "  2.33428678e-01 6.59367785e-01 0.00000000e+00 2.72980501e-01]\n",
      " [2.39420193e-01 2.82039313e-01 3.28660436e-01 1.59650116e-01\n",
      "  1.50271525e-01 3.97815663e-01 2.69774376e-01 4.40111421e-01]\n",
      " [8.15420501e-01 6.33732690e-01 6.86623832e-01 4.10735637e-01\n",
      "  2.14774282e-01 0.00000000e+00 5.77993879e-01 6.54596100e-01]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.59403303e-04 1.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "index_data = pd.read_csv( 'raw2.csv', names = index_names ) # read file, insert header row\n",
    "index_data.dropna( inplace = True ) # this removes rows with >=1 #na, being 234/1,304 data points in v1 dataset, inplace= True, 'do operation inplace and return None.''\n",
    "# index_data.describe() #prints some table metrics, not part of any calculation hereafter.\n",
    "# print(\"index_data size is \")\n",
    "# print(index_data.size)\n",
    "# print(\"index_data:\")\n",
    "# print(index_data)\n",
    "trainingData = index_data[ subset ].values\n",
    "print(\"trainingData size is \")\n",
    "print(trainingData.size)\n",
    "# print(trainingData)\n",
    "trainingData = minmax_scale( trainingData, feature_range=(0, 1), axis=0, copy=True )\n",
    "print(trainingData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
